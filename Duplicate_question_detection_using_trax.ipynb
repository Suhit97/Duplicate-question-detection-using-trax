{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Duplicate question detection using trax.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPW5Jc3hoQv2jwljoIP+EYj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Suhit97/Duplicate-question-detection-using-trax/blob/main/Duplicate_question_detection_using_trax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8SBmyon2fDN",
        "outputId": "c47f281b-39ee-483f-e846-2ad8eb47b5cd"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqqD0uFw_QWE",
        "outputId": "6c58bcfe-329b-4994-c625-d610dbda4505"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/NER"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/NER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0oYOY1WDEph"
      },
      "source": [
        "## Importing the Quora Duplicate question dataset using kaggle api"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "_4mBozQt_YkX",
        "outputId": "ffa052e9-9ba9-484f-f7ff-4c28e42d8b48"
      },
      "source": [
        "\r\n",
        "\r\n",
        "# Colab's file access feature\r\n",
        "from google.colab import files\r\n",
        "\r\n",
        "#retrieve uploaded file\r\n",
        "uploaded = files.upload()\r\n",
        "\r\n",
        "#print results\r\n",
        "for fn in uploaded.keys():\r\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\r\n",
        "      name=fn, length=len(uploaded[fn])))\r\n",
        "  \r\n",
        "# Then move kaggle.json into the folder where the API expects to find it.\r\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2b6a67f4-a2d6-47a6-8f94-1090bebead89\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2b6a67f4-a2d6-47a6-8f94-1090bebead89\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 67 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUQ39TttBizZ",
        "outputId": "b6a7c3ab-2ba1-4aa9-f96a-634b49fe2d12"
      },
      "source": [
        "!kaggle competitions download -c quora-question-pairs -p /content/gdrive/My\\ Drive/NER"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "Downloading train.csv.zip to /content/gdrive/My Drive/NER\n",
            " 80% 17.0M/21.2M [00:00<00:00, 19.3MB/s]\n",
            "100% 21.2M/21.2M [00:00<00:00, 25.6MB/s]\n",
            "Downloading test.csv.zip to /content/gdrive/My Drive/NER\n",
            " 99% 113M/114M [00:02<00:00, 70.7MB/s]\n",
            "100% 114M/114M [00:02<00:00, 48.9MB/s]\n",
            "Downloading sample_submission.csv.zip to /content/gdrive/My Drive/NER\n",
            " 20% 1.00M/4.95M [00:00<00:00, 10.2MB/s]\n",
            "100% 4.95M/4.95M [00:00<00:00, 31.5MB/s]\n",
            "test.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xb9Luk22uSx"
      },
      "source": [
        "import zipfile\r\n",
        "\r\n",
        "data_zip1 = 'test.csv.zip'\r\n",
        "zip_ref1 = zipfile.ZipFile(data_zip1, 'r')\r\n",
        "zip_ref1.extractall('data')\r\n",
        "zip_ref1.close()\r\n",
        "\r\n",
        "data_zip2 = 'train.csv.zip'\r\n",
        "zip_ref2 = zipfile.ZipFile(data_zip2, 'r')\r\n",
        "zip_ref2.extractall('data')\r\n",
        "zip_ref2.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1G1p-IIHEbxK",
        "outputId": "c592c6cb-6c94-4dcd-8fc9-22ce47eb979a"
      },
      "source": [
        "!pip install trax"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting trax\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/51/305b839f51d53abb393777f743e497d27bb341478f3fdec4d6ddaccc9fb5/trax-1.3.7-py2.py3-none-any.whl (521kB)\n",
            "\r\u001b[K     |▋                               | 10kB 7.8MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20kB 11.9MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30kB 15.4MB/s eta 0:00:01\r\u001b[K     |██▌                             | 40kB 10.3MB/s eta 0:00:01\r\u001b[K     |███▏                            | 51kB 5.5MB/s eta 0:00:01\r\u001b[K     |███▊                            | 61kB 6.0MB/s eta 0:00:01\r\u001b[K     |████▍                           | 71kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 81kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 92kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 102kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 112kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 122kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 133kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 143kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 153kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 163kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 174kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 184kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 194kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 204kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 215kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 225kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 235kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 245kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 256kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 266kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 276kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 286kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 296kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 307kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 317kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 327kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 337kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 348kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 358kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 368kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 378kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 389kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 399kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 409kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 419kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 430kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 440kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 450kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 460kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 471kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 481kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 491kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 501kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 512kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 522kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from trax) (1.19.4)\n",
            "Collecting tensorflow-text\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/b8/5884204f7c2da639a3061fe3a0c41a06bb80bf7976fa7d407e1d628e38e9/tensorflow_text-2.4.2-cp36-cp36m-manylinux1_x86_64.whl (3.4MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 20.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from trax) (5.4.8)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.6/dist-packages (from trax) (4.0.1)\n",
            "Collecting t5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/c6/2ea21c983ae27553a798829a533349de5df99678cfd3fd8d313ae30b063f/t5-0.8.1-py3-none-any.whl (214kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 34.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from trax) (0.10.0)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.6/dist-packages (from trax) (0.2.7)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.6/dist-packages (from trax) (0.1.57+cuda101)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (from trax) (0.17.3)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from trax) (0.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from trax) (1.15.0)\n",
            "Collecting funcsigs\n",
            "  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from trax) (1.4.1)\n",
            "Requirement already satisfied: tensorflow<2.5,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-text->trax) (2.4.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-text->trax) (0.10.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (0.26.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (2.23.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (4.41.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (0.3.3)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (0.8)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (3.12.4)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (2.3)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (20.3.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (1.1.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->trax) (0.1.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from t5->trax) (0.22.2.post1)\n",
            "Collecting tfds-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/7a/826891fddc8f35c29d52eb4bda3a545112f07b9366b0b4ff6b572b39e41d/tfds_nightly-4.2.0.dev202101090106-py3-none-any.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 41.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from t5->trax) (1.7.0+cu101)\n",
            "Collecting transformers>=2.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 29.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: babel in /usr/local/lib/python3.6/dist-packages (from t5->trax) (2.9.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from t5->trax) (3.2.5)\n",
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/c4/8e948f601a4f9609e8b2b58f31966cb13cf17b940b82aa3e767f01c42c52/sacrebleu-1.4.14-py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.4MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 24.4MB/s \n",
            "\u001b[?25hCollecting rouge-score\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/56/a81022436c08b9405a5247b71635394d44fe7e1dbedc4b28c740e09c2840/rouge_score-0.0.4-py2.py3-none-any.whl\n",
            "Collecting mesh-tensorflow[transformer]>=0.1.13\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/20/23bbc94034e16bb1ace73e9e7922226e31d6d36b88dcfa257d2c59b3f465/mesh_tensorflow-0.1.18-py3-none-any.whl (361kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 33.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from t5->trax) (1.1.5)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.6/dist-packages (from jax->trax) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.6/dist-packages (from jaxlib->trax) (1.12)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym->trax) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym->trax) (1.5.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (2.4.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (2.4.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (0.2.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (1.6.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (0.3.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (1.1.2)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (2.10.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (0.36.2)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (1.32.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (1.12.1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (3.7.4.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets->trax) (1.52.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (2020.12.5)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->trax) (3.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-datasets->trax) (51.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->t5->trax) (1.0.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 39.6MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 35.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5->trax) (20.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5->trax) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->t5->trax) (3.0.12)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.6/dist-packages (from babel->t5->trax) (2018.9)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->t5->trax) (2.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (3.3.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (0.4.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (1.7.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (1.17.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.7.0->t5->trax) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers>=2.7.0->t5->trax) (2.4.7)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (3.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (4.2.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->trax) (0.4.8)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=e0901899e1819609fd27d41ad457beb7c6cca371eff7394287aad7066ca72a6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tensorflow-text, tfds-nightly, sacremoses, tokenizers, transformers, portalocker, sacrebleu, sentencepiece, rouge-score, mesh-tensorflow, t5, funcsigs, trax\n",
            "Successfully installed funcsigs-1.0.2 mesh-tensorflow-0.1.18 portalocker-2.0.0 rouge-score-0.0.4 sacrebleu-1.4.14 sacremoses-0.0.43 sentencepiece-0.1.94 t5-0.8.1 tensorflow-text-2.4.2 tfds-nightly-4.2.0.dev202101090106 tokenizers-0.9.4 transformers-4.1.1 trax-1.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip7xxOvYDR5h"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUos7b4OCVIO",
        "outputId": "e88b84e9-3e73-4db5-d341-7d25eb9724d7"
      },
      "source": [
        "import os\r\n",
        "import nltk\r\n",
        "import trax\r\n",
        "from trax import layers as tl\r\n",
        "from trax.supervised import training\r\n",
        "from trax.fastmath import numpy as fastnp\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import random as rnd\r\n",
        "\r\n",
        "\r\n",
        "nltk.download('wordnet')\r\n",
        "\r\n",
        "nltk.download('punkt')\r\n",
        "\r\n",
        "nltk.download('universal_tagset')\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "l5xlQTsPEZxs",
        "outputId": "1056a190-ccc6-4ae2-fb8b-cae4650b98d6"
      },
      "source": [
        "data = pd.read_csv(\"data/train.csv\")\r\n",
        "N=len(data)\r\n",
        "print('Number of question pairs: ', N)\r\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of question pairs:  404290\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  ...                                          question2 is_duplicate\n",
              "0   0     1  ...  What is the step by step guide to invest in sh...            0\n",
              "1   1     3  ...  What would happen if the Indian government sto...            0\n",
              "2   2     5  ...  How can Internet speed be increased by hacking...            0\n",
              "3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n",
              "4   4     9  ...            Which fish would survive in salt water?            0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBq1hqC-FInW",
        "outputId": "6d2a835b-4c7f-4500-856c-92e0b596e8b4"
      },
      "source": [
        "N_train = 300000\r\n",
        "N_test  = 10*1024\r\n",
        "data_train = data[:N_train]\r\n",
        "data_test  = data[N_train:N_train+N_test]\r\n",
        "print(\"Train set:\", len(data_train), \"Test set:\", len(data_test))\r\n",
        "del(data) # remove to free memory"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set: 300000 Test set: 10240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4f1mKfjFZfO",
        "outputId": "b68c9e34-a013-4c23-d481-df068741c06f"
      },
      "source": [
        "td_index = (data_train['is_duplicate'] == 1).to_numpy()\r\n",
        "td_index = [i for i, x in enumerate(td_index) if x] \r\n",
        "print('number of duplicate questions: ', len(td_index))\r\n",
        "print('indexes of first ten duplicate questions:', td_index[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of duplicate questions:  111473\n",
            "indexes of first ten duplicate questions: [5, 7, 11, 12, 13, 15, 16, 18, 20, 29]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXnT4Us8FlGp",
        "outputId": "189eef2b-505d-43ed-8491-59b00e5a6066"
      },
      "source": [
        "print(data_train['question1'][5])  #  Example of question duplicates (first one in data)\r\n",
        "print(data_train['question2'][5])\r\n",
        "print('is_duplicate: ', data_train['is_duplicate'][5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
            "I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\n",
            "is_duplicate:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbGy0ZqtFtq8"
      },
      "source": [
        "Q1_train_words = np.array(data_train['question1'][td_index])\r\n",
        "Q2_train_words = np.array(data_train['question2'][td_index])\r\n",
        "\r\n",
        "Q1_test_words = np.array(data_test['question1'])\r\n",
        "Q2_test_words = np.array(data_test['question2'])\r\n",
        "y_test  = np.array(data_test['is_duplicate'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6SEMIKFF7Mx",
        "outputId": "8238593b-d834-4d83-f2b6-bb840b38964f"
      },
      "source": [
        "print('TRAINING QUESTIONS:\\n')\r\n",
        "print('Question 1: ', Q1_train_words[0])\r\n",
        "print('Question 2: ', Q2_train_words[0], '\\n')\r\n",
        "print('Question 1: ', Q1_train_words[5])\r\n",
        "print('Question 2: ', Q2_train_words[5], '\\n')\r\n",
        "\r\n",
        "print('TESTING QUESTIONS:\\n')\r\n",
        "print('Question 1: ', Q1_test_words[0])\r\n",
        "print('Question 2: ', Q2_test_words[0], '\\n')\r\n",
        "print('is_duplicate =', y_test[0], '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINING QUESTIONS:\n",
            "\n",
            "Question 1:  Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
            "Question 2:  I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me? \n",
            "\n",
            "Question 1:  What would a Trump presidency mean for current international master’s students on an F1 visa?\n",
            "Question 2:  How will a Trump presidency affect the students presently in US or planning to study in US? \n",
            "\n",
            "TESTING QUESTIONS:\n",
            "\n",
            "Question 1:  What were some of the troubles you have faced during and after your 9 months period of pregnancy?\n",
            "Question 2:  What is the difference between neural circuit and neural system? \n",
            "\n",
            "is_duplicate = 0 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo6bCxkuF_Vd"
      },
      "source": [
        "#create arrays\r\n",
        "Q1_train = np.empty_like(Q1_train_words)\r\n",
        "Q2_train = np.empty_like(Q2_train_words)\r\n",
        "\r\n",
        "Q1_test = np.empty_like(Q1_test_words)\r\n",
        "Q2_test = np.empty_like(Q2_test_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD_nml6RHhRx",
        "outputId": "c43b621f-f58d-48d1-8000-b052a27b628d"
      },
      "source": [
        "from collections import defaultdict\r\n",
        "\r\n",
        "vocab = defaultdict(lambda: 0)\r\n",
        "vocab['<PAD>'] = 1\r\n",
        "\r\n",
        "for idx in range(len(Q1_train_words)):\r\n",
        "    Q1_train[idx] = nltk.word_tokenize(Q1_train_words[idx])\r\n",
        "    Q2_train[idx] = nltk.word_tokenize(Q2_train_words[idx])\r\n",
        "    q = Q1_train[idx] + Q2_train[idx]\r\n",
        "    for word in q:\r\n",
        "        if word not in vocab:\r\n",
        "            vocab[word] = len(vocab) + 1\r\n",
        "print('The length of the vocabulary is:', len(vocab))\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of the vocabulary is: 36352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNTGY-ImJSK4",
        "outputId": "e3d9906c-90d3-40aa-ed1d-2801f1c96229"
      },
      "source": [
        "print(vocab['<PAD>'])\r\n",
        "print(vocab['Astrology'])\r\n",
        "print(vocab['Astronomy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GNtf9B5JbV3",
        "outputId": "aaabb6b3-7ffc-41f9-8362-525a1c69a1fe"
      },
      "source": [
        "for idx in range(len(Q1_test_words)): \r\n",
        "    Q1_test[idx] = nltk.word_tokenize(Q1_test_words[idx])\r\n",
        "    Q2_test[idx] = nltk.word_tokenize(Q2_test_words[idx])\r\n",
        "\r\n",
        "print('Train set has reduced to: ', len(Q1_train) ) \r\n",
        "print('Test set length: ', len(Q1_test) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set has reduced to:  111473\n",
            "Test set length:  10240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ncZ2qQZKTTc"
      },
      "source": [
        "## Converting Questions to tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6cxFiApJsiI"
      },
      "source": [
        "# Converting questions to array of integers\r\n",
        "for i in range(len(Q1_train)):\r\n",
        "    Q1_train[i] = [vocab[word] for word in Q1_train[i]]\r\n",
        "    Q2_train[i] = [vocab[word] for word in Q2_train[i]]\r\n",
        "\r\n",
        "        \r\n",
        "for i in range(len(Q1_test)):\r\n",
        "    Q1_test[i] = [vocab[word] for word in Q1_test[i]]\r\n",
        "    Q2_test[i] = [vocab[word] for word in Q2_test[i]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyabdDxfMEdK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6I4YgvWKnEZ",
        "outputId": "88cb9911-0a41-422f-b66b-6bd58dc93e27"
      },
      "source": [
        "print('first question in the train set:\\n')\r\n",
        "print(Q1_train_words[0], '\\n') \r\n",
        "print('encoded version:')\r\n",
        "print(Q1_train[0],'\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first question in the train set:\n",
            "\n",
            "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me? \n",
            "\n",
            "encoded version:\n",
            "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcIvF8rMMDaL"
      },
      "source": [
        "## *validation split*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu_wBz0_K0ha",
        "outputId": "4d12a2a8-0677-47cc-c64e-edc3dcb1a424"
      },
      "source": [
        "cut_off = int(len(Q1_train)*.8)\r\n",
        "train_Q1, train_Q2 = Q1_train[:cut_off], Q2_train[:cut_off]\r\n",
        "val_Q1, val_Q2 = Q1_train[cut_off: ], Q2_train[cut_off:]\r\n",
        "print('Number of duplicate questions: ', len(Q1_train))\r\n",
        "print(\"The length of the training set is:  \", len(train_Q1))\r\n",
        "print(\"The length of the validation set is: \", len(val_Q1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of duplicate questions:  111473\n",
            "The length of the training set is:   89178\n",
            "The length of the validation set is:  22295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDpoQnbLNxsi"
      },
      "source": [
        "## *data generator*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OOwQcIlL9RP"
      },
      "source": [
        "def data_generator(Q1, Q2, batch_size, pad=1, shuffle=True):\r\n",
        "    \r\n",
        "\r\n",
        "    input1 = []\r\n",
        "    input2 = []\r\n",
        "    idx = 0\r\n",
        "    len_q = len(Q1)\r\n",
        "    question_indexes = [*range(len_q)]\r\n",
        "    \r\n",
        "    if shuffle:\r\n",
        "        rnd.shuffle(question_indexes)\r\n",
        "    \r\n",
        "    while True:\r\n",
        "        if idx >= len_q:\r\n",
        "            \r\n",
        "            idx = len_q\r\n",
        "            if shuffle:\r\n",
        "                rnd.shuffle(question_indexes)\r\n",
        "        \r\n",
        "        q1 = Q1[question_indexes[idx]]\r\n",
        "        q2 = Q2[question_indexes[idx]]\r\n",
        "        \r\n",
        "        idx += 1\r\n",
        "        input1.append(q1)\r\n",
        "        input2.append(q2)\r\n",
        "        \r\n",
        "        if len(input1) == batch_size:\r\n",
        "            ## determine max_len as the longest question in input1 & input 2\r\n",
        "            max_len = max(max([len(q) for q in input1]),max([len(q) for q in input2]))\r\n",
        "            max_len = 2**int(np.ceil(np.log2(max_len)))\r\n",
        "            b1 = []\r\n",
        "            b2 = []\r\n",
        "        \r\n",
        "            for q1, q2 in zip(input1, input2):\r\n",
        "                q1 = q1 + [pad] * (max_len - len(q1))\r\n",
        "                q2 = q2 + [pad] * (max_len - len(q2))\r\n",
        "                b1.append(q1)\r\n",
        "                b2.append(q2)\r\n",
        "            \r\n",
        "            yield np.array(b1), np.array(b2)\r\n",
        "    \r\n",
        "            input1, input2 = [], []  # reset the batches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYH3oiCIMO14",
        "outputId": "34512c4f-5414-47ca-89c3-71f7816133c9"
      },
      "source": [
        "\r\n",
        "batch_size = 3\r\n",
        "res1, res2 = next(data_generator(train_Q1, train_Q2, batch_size))\r\n",
        "print(\"First questions  : \",'\\n', res1, '\\n')\r\n",
        "print(\"Second questions : \",'\\n', res2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First questions  :  \n",
            " [[   30   156  1585   254   924    28    56   602    21     1     1     1\n",
            "      1     1     1     1]\n",
            " [   30    87    78   409  1811    72    90    21     1     1     1     1\n",
            "      1     1     1     1]\n",
            " [   30    16  1136  2472  4560  1772 11473    21     1     1     1     1\n",
            "      1     1     1     1]] \n",
            "\n",
            "Second questions :  \n",
            " [[   30   156 13892   254  5909    21     1     1     1     1     1     1\n",
            "      1     1     1     1]\n",
            " [  219   119  8247    78   409   407    72    90    21     1     1     1\n",
            "      1     1     1     1]\n",
            " [   86   156    78  1136  2472   131    78  4560   156 26263    21     1\n",
            "      1     1     1     1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3HigY4SP3Bh"
      },
      "source": [
        "## Making the Siamese model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRlwCNoYPHme"
      },
      "source": [
        "def Siamese(vocab_size = len(vocab), d_model = 128, mode='train'):\r\n",
        "    def normalize(x):  # normalizes the vectors to have L2 norm 1\r\n",
        "        return x / fastnp.sqrt(fastnp.sum(x * x, axis=-1, keepdims=True))\r\n",
        "    \r\n",
        "    q_processor = tl.Serial(  # Processor will run on Q1 and Q2.\r\n",
        "        tl.Embedding(vocab_size, d_model), # Embedding layer\r\n",
        "        tl.LSTM(d_model), # LSTM layer\r\n",
        "        tl.Mean(axis=1), # Mean over columns\r\n",
        "        tl.Fn('Normalize', lambda x: normalize(x))  # Apply normalize function\r\n",
        "             )  # Returns one vector of shape [batch_size, d_model].\r\n",
        "\r\n",
        "    model = tl.Parallel(q_processor, q_processor)\r\n",
        "\r\n",
        "    return model\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyMjV1zVSjNv",
        "outputId": "b0602439-3e7a-4a60-ad41-ee2ddd97d8fc"
      },
      "source": [
        "model = Siamese()\r\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parallel_in2_out2[\n",
            "  Serial[\n",
            "    Embedding_41794_128\n",
            "    LSTM_128\n",
            "    Mean\n",
            "    Normalize\n",
            "  ]\n",
            "  Serial[\n",
            "    Embedding_41794_128\n",
            "    LSTM_128\n",
            "    Mean\n",
            "    Normalize\n",
            "  ]\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2HdQ-mtS6gx"
      },
      "source": [
        "## Hard Negative Mining to improve the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILz7sO_jSn-a"
      },
      "source": [
        "def TripletLossFn(v1, v2, margin=0.25):\r\n",
        "    \"\"\"\r\n",
        "    Args:\r\n",
        "        v1 (numpy.ndarray): Array with dimension (batch_size, model_dimension) associated to Q1.\r\n",
        "        v2 (numpy.ndarray): Array with dimension (batch_size, model_dimension) associated to Q2.\r\n",
        "        margin (float, optional): Desired margin. Defaults to 0.25.\r\n",
        "\r\n",
        "    \"\"\"\r\n",
        "    # use fastnp to take the dot product of the two batches (don't forget to transpose the second argument)\r\n",
        "    scores = fastnp.dot(v1, v2.T)  # pairwise cosine sim\r\n",
        "    # calculate new batch size\r\n",
        "    batch_size = len(scores)\r\n",
        "    # use fastnp to grab all postive `diagonal` entries in `scores`\r\n",
        "    positive = fastnp.diagonal(scores)  # the positive ones (duplicates)\r\n",
        "    # multiply `fastnp.eye(batch_size)` with 2.0 and subtract it out of `scores`\r\n",
        "    negative_without_positive = scores - 2.0 * fastnp.eye(batch_size)\r\n",
        "    # take the row by row `max` of `negative_without_positive`. \r\n",
        "    \r\n",
        "    closest_negative = negative_without_positive.max(axis=1)\r\n",
        "    # subtract `fastnp.eye(batch_size)` out of 1.0 and do element-wise multiplication with `scores`\r\n",
        "    negative_zero_on_duplicate = scores * (1.0 - fastnp.eye(batch_size))\r\n",
        "    # use `fastnp.sum` on `negative_zero_on_duplicate` for `axis=1` and divide it by `(batch_size - 1)` \r\n",
        "    mean_negative = np.sum(negative_zero_on_duplicate, axis=1) / (batch_size-1)\r\n",
        "    # compute `fastnp.maximum` among 0.0 and `A`\r\n",
        "    # A = subtract `positive` from `margin` and add `closest_negative` \r\n",
        "    triplet_loss1 = fastnp.maximum(0.0, margin - positive + closest_negative)\r\n",
        "    # compute `fastnp.maximum` among 0.0 and `B`\r\n",
        "    # B = subtract `positive` from `margin` and add `mean_negative`\r\n",
        "    triplet_loss2 = fastnp.maximum(0.0, margin - positive + mean_negative)\r\n",
        "    # add the two losses together and take the `fastnp.mean` of it\r\n",
        "    triplet_loss = fastnp.mean(triplet_loss1 + triplet_loss2)\r\n",
        "    \r\n",
        "    \r\n",
        "    \r\n",
        "    return triplet_loss\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eajWcHhuVQds",
        "outputId": "8a7eb524-792b-4b93-bc9b-d2be65739e23"
      },
      "source": [
        "v1 = np.array([[0.26726124, 0.53452248, 0.80178373],[0.5178918 , 0.57543534, 0.63297887]])\r\n",
        "v2 = np.array([[ 0.26726124,  0.53452248,  0.80178373],[-0.5178918 , -0.57543534, -0.63297887]])\r\n",
        "TripletLossFn(v2,v1)\r\n",
        "print(\"Triplet Loss:\", TripletLossFn(v2,v1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Triplet Loss: 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFjDGZL2VTpy"
      },
      "source": [
        "# To make a layer out of a function with no trainable variables, use tl.F\r\n",
        "from functools import partial\r\n",
        "\r\n",
        "def TripletLoss(margin=0.25):\r\n",
        "    triplet_loss_fn = partial(TripletLossFn, margin=margin)\r\n",
        "    return tl.Fn('TripletLoss', triplet_loss_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D39yc4c5Ogv"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmZl5t5bVrFr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0e80057-8fcc-4a20-9b01-32723076795f"
      },
      "source": [
        "batch_size = 256\r\n",
        "train_generator = data_generator(train_Q1, train_Q2, batch_size, vocab['<PAD>'])\r\n",
        "val_generator = data_generator(val_Q1, val_Q2, batch_size, vocab['<PAD>'])\r\n",
        "print('train_Q1.shape ', train_Q1.shape)\r\n",
        "print('val_Q1.shape   ', val_Q1.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_Q1.shape  (89178,)\n",
            "val_Q1.shape    (22295,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wni3fM4S5Nii"
      },
      "source": [
        "lr_schedule = trax.lr.warmup_and_rsqrt_decay(400, 0.01)\r\n",
        "\r\n",
        "def train_model(Siamese, TripletLoss, lr_schedule, train_generator=train_generator, val_generator=val_generator, output_dir='data'):\r\n",
        "    \r\n",
        "    output_dir = os.path.expanduser(output_dir)\r\n",
        "\r\n",
        "    train_task = training.TrainTask(\r\n",
        "          labeled_data=train_generator,            # Use generator (train)\r\n",
        "          loss_layer=TripletLoss(),                # Use triplet loss. Don't forget to instantiate this object\r\n",
        "          optimizer=trax.optimizers.Adam(0.01),    # Don't forget to add the learning rate parameter\r\n",
        "          lr_schedule=lr_schedule                  # Use Trax multifactor schedule function\r\n",
        "    )\r\n",
        "\r\n",
        "    eval_task = training.EvalTask(\r\n",
        "          labeled_data=val_generator,       # Use generator (val)\r\n",
        "          metrics=[TripletLoss()]          # Use triplet loss. Don't forget to instantiate this object\r\n",
        "    )\r\n",
        "    \r\n",
        "  \r\n",
        "\r\n",
        "    training_loop = training.Loop(Siamese(),\r\n",
        "                                  train_task,\r\n",
        "                                  eval_tasks=eval_task,\r\n",
        "                                  output_dir=output_dir)\r\n",
        "  \r\n",
        "\r\n",
        "    return training_loop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWQnVhv15sZy",
        "outputId": "e35ed7b4-8093-4674-b23c-5b27e01880d4"
      },
      "source": [
        "train_steps = 10\r\n",
        "training_loop = train_model(Siamese, TripletLoss, lr_schedule)\r\n",
        "training_loop.run(train_steps)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Step      1: Total number of trainable weights: 5481216\n",
            "Step      1: Ran 1 train steps in 6.62 secs\n",
            "Step      1: train TripletLoss |  0.49999812\n",
            "Step      1: eval  TripletLoss |  0.49999037\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijoC3SgMDgAR"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFZcEv-V5w0G"
      },
      "source": [
        "model = Siamese()\r\n",
        "model.init_from_file('data/model.pkl.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFalXEXZDl6k"
      },
      "source": [
        "def classify(test_Q1, test_Q2, y, threshold, model, vocab, data_generator=data_generator, batch_size=64):\r\n",
        "    \r\n",
        "    accuracy = 0\r\n",
        "    for i in range(0, len(test_Q1), batch_size):\r\n",
        "       \r\n",
        "        q1, q2 = next(data_generator(test_Q1[i:i + batch_size], test_Q2[i:i + batch_size], batch_size, vocab['<PAD>'], shuffle=False))\r\n",
        "        # use batch size chuncks of actual output targets (same syntax as example above)\r\n",
        "        y_test = y[i:i + batch_size]\r\n",
        "        # Call the model\r\n",
        "        v1, v2 = model((q1, q2))\r\n",
        "\r\n",
        "        for j in range(batch_size):\r\n",
        "            # take dot product to compute cos similarity of each pair of entries, v1[j], v2[j]\r\n",
        "            # don't forget to transpose the second argument\r\n",
        "            d = np.dot(v1[j], v2[j].T)\r\n",
        "            # is d greater than the threshold?\r\n",
        "            res = d > threshold\r\n",
        "            # increment accurancy if y_test is equal `res`\r\n",
        "            accuracy += (y_test[j] == res)\r\n",
        "    \r\n",
        "    accuracy = accuracy / len(test_Q1)\r\n",
        "    \r\n",
        "    \r\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSl_IxHwEXZr",
        "outputId": "336839e0-f002-42ea-b4e8-204a038d1e7c"
      },
      "source": [
        "accuracy = classify(Q1_test,Q2_test, y_test, 0.7, model, vocab, batch_size = 512) \r\n",
        "print(\"Accuracy\", accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.3765625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc3Tni8jEjMu"
      },
      "source": [
        "def predict(question1, question2, threshold, model, vocab, data_generator=data_generator, verbose=False):\r\n",
        "    \r\n",
        "    q1 = nltk.word_tokenize(question1)  \r\n",
        "    q2 = nltk.word_tokenize(question2)  \r\n",
        "    Q1, Q2 = [], []\r\n",
        "    for word in q1:  \r\n",
        "        # increment by checking the 'word' index in `vocab`\r\n",
        "        Q1 += [vocab[word]]\r\n",
        "    for word in q2:  # encode q2\r\n",
        "        # increment by checking the 'word' index in `vocab`\r\n",
        "        Q2 += [vocab[word]]\r\n",
        "        \r\n",
        "    # Call the data generator (built in Ex 01) using next()\r\n",
        "    # pass [Q1] & [Q2] as Q1 & Q2 arguments of the data generator. Set batch size as 1\r\n",
        "    Q1, Q2 = next(data_generator([Q1], [Q2], 1, vocab['<PAD>']))\r\n",
        "    # Call the model\r\n",
        "    v1, v2 = model((Q1, Q2))\r\n",
        "    # take dot product to compute cos similarity of each pair of entries, v1, v2\r\n",
        "    # don't forget to transpose the second argument\r\n",
        "    d = np.dot(v1[0], v2[0].T)\r\n",
        "    # is d greater than the threshold?\r\n",
        "    res = d > threshold\r\n",
        "    \r\n",
        "\r\n",
        "    \r\n",
        "    if(verbose):\r\n",
        "        print(\"Q1  = \", Q1, \"\\nQ2  = \", Q2)\r\n",
        "        print(\"d   = \", d)\r\n",
        "        print(\"res = \", res)\r\n",
        "\r\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gw4i3cAE_fk",
        "outputId": "be6e1d45-bc20-483b-ecbe-61583458fbf4"
      },
      "source": [
        "question1 = \"When will I see you?\"\r\n",
        "question2 = \"When can I see you again?\"\r\n",
        "# 1 means it is duplicated, 0 otherwise\r\n",
        "predict(question1 , question2, 0.7, model, vocab, verbose = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q1  =  [[585  76   4  46  53  21   1   1]] \n",
            "Q2  =  [[ 585   33    4   46   53 7287   21    1]]\n",
            "d   =  0.9999717\n",
            "res =  True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kX80IGuxFD9p",
        "outputId": "e54278fe-e4b5-4c7e-f47c-e22e611a3568"
      },
      "source": [
        "question1 = \"Do they enjoy eating the dessert?\"\r\n",
        "question2 = \"Do they like hiking in the desert?\"\r\n",
        "# 1 means it is duplicated, 0 otherwise\r\n",
        "predict(question1 , question2, 0.7, model, vocab, verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q1  =  [[  443  1145  3158  1169    78 29070    21     1]] \n",
            "Q2  =  [[  443  1145    60 15323    28    78  7438    21]]\n",
            "d   =  0.9999722\n",
            "res =  True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHef6O51FMbN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}